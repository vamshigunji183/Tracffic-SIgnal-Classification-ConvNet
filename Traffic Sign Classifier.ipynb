{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (39209,) (12630, 32, 32, 3) (12630,)\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'train.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (12630, 32, 32, 3)\n",
      "dict_items([(0, 210), (1, 2220), (2, 2250), (3, 1410), (4, 1980), (5, 1860), (6, 420), (7, 1440), (8, 1410), (9, 1470), (10, 2010), (11, 1320), (12, 2100), (13, 2160), (14, 780), (15, 630), (16, 420), (17, 1110), (18, 1200), (19, 210), (20, 360), (21, 330), (22, 390), (23, 510), (24, 270), (25, 1500), (26, 600), (27, 240), (28, 540), (29, 270), (30, 450), (31, 780), (32, 240), (33, 689), (34, 420), (35, 1200), (36, 390), (37, 210), (38, 2070), (39, 300), (40, 360), (41, 240), (42, 240)])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "from collections import Counter\n",
    "\n",
    "c = Counter( y_train )\n",
    "\n",
    "print( c.items() )\n",
    "# Shows that training set is uneven distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 39209\n",
      "Number of testing examples = 12630\n",
      "Image data shape = 32x32x3\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "### Replace each question mark with the appropriate value.\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = 39209\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = 12630\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = '32x32x3'\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = 43\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Data exploration visualization goes here.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min and Max values original train dataset 53 255\n",
      "Min and Max values normalized train dataset -0.292156862745098 0.5\n",
      "[35 38  4 38 35 38 32  7 21 25 13 13 11  5  9  4 13 23 18  3 25  6 11 35\n",
      "  1  4 29  2  5  3  2 12  1 39  9  8 10  8 28  7  5  7 30 10  1 18  2  3\n",
      " 26 14]\n"
     ]
    }
   ],
   "source": [
    "### Preprocess the data here.\n",
    "\n",
    "## Normalize the data to zero mean and equal variance using pixel depth\n",
    "\n",
    "print(\"Min and Max values original train dataset\", np.amin(X_train[0]), np.amax(X_train[0]))\n",
    "\n",
    "pixel_depth = 255\n",
    "X_train_norm = (X_train.astype(float))/255 -0.5\n",
    "X_test_norm = (X_test.astype(float))/255 -0.5\n",
    "# X_train_norm = X_train.astype(float) - \n",
    "#                     pixel_depth / 2) / pixel_depth\n",
    "\n",
    "# X_test_norm = (X_test.astype(float) - \n",
    "#                     pixel_depth / 2) / pixel_depth\n",
    "\n",
    "print(\"Min and Max values normalized train dataset\", np.amin(X_train_norm[0]), np.amax(X_train_norm[0]))\n",
    "\n",
    "## Shuffle training data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train_norm, y_train)\n",
    "\n",
    "### Feel free to use as many code cells as needed.\n",
    "print(y_train[:50])\n",
    "# Yes! Data is shuffled now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gvvam\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset (31367, 32, 32, 3) (31367,)\n",
      "Validation dataset (7842, 32, 32, 3) (7842,)\n"
     ]
    }
   ],
   "source": [
    "### Generate additional data (OPTIONAL!)\n",
    "### and split the data into training/validation/testing sets here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=2275)\n",
    "\n",
    "print(\"train dataset\", X_train.shape, y_train.shape)\n",
    "print(\"Validation dataset\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gvvam\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "### Define your architecture here.\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "dropout = 0.70\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets start with LeNet architecture\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x, add_dropout = False):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', name='conv1')\n",
    "\n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID', name='conv2') + conv2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # Add another convolution layer\n",
    "    \n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "\n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Add dropout\n",
    "    if add_dropout:\n",
    "        fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Add dropout\n",
    "    if add_dropout:\n",
    "        fc2 = tf.nn.dropout(fc2, dropout)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    regularizers = (tf.nn.l2_loss(fc1_W) + tf.nn.l2_loss(fc1_b) + tf.nn.l2_loss(fc2_W) + tf.nn.l2_loss(fc2_b) + tf.nn.l2_loss(fc3_W) + tf.nn.l2_loss(fc3_b))\n",
    "    \n",
    "    return logits, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create placeholders for input tensors\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "num_labels = 43\n",
    "# sparse_labels = tf.reshape(y, [-1, 1])\n",
    "# derived_size = tf.shape(sparse_labels)[0]\n",
    "# indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "# concated = tf.concat(1, [indices, sparse_labels])\n",
    "# outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\n",
    "# one_hot_y = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-b3f65eab7a7a>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define learning rate and the training pipeline \n",
    "rate = 0.001 # Learning rate\n",
    "factor = 5e-4 # Regularization factor\n",
    "\n",
    "logits, regularizers = LeNet(x, add_dropout = False)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# L2 regularization for the fully connected parameters. Add regularization to loss term\n",
    "\n",
    "loss_operation += factor * regularizers\n",
    "    \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "softmax=tf.nn.softmax(logits)\n",
    "prediction=tf.argmax(logits,1)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss = 0\n",
    "    pred = []\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        loss = sess.run(loss_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        predictions = sess.run(prediction, feed_dict={x: batch_x, y: batch_y})\n",
    "        pred.append(predictions)\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x)) \n",
    "    return total_accuracy / num_examples, pred, total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-57ff34f138d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mvalidation_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mtraining_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mval_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-90cc24bf16cc>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(X_data, y_data)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train your model here.\n",
    "val_accuracy = []\n",
    "train_accuracy = []\n",
    "val_loss =[]\n",
    "train_loss = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy, _ , validation_loss = evaluate(X_valid, y_valid)\n",
    "        training_accuracy, _, training_loss = evaluate(X_train, y_train)\n",
    "        val_accuracy.append(validation_accuracy)\n",
    "        val_loss.append(validation_loss)\n",
    "        train_accuracy.append(training_accuracy)\n",
    "        train_loss.append(training_loss)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracies \n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(121)\n",
    "line_one, = plt.plot(val_accuracy, label='Validation')\n",
    "line_two, = plt.plot(train_accuracy, label = 'Training')\n",
    "plt.ylabel('Accuracy values')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.legend(handles=[line_one, line_two])\n",
    "\n",
    "a=fig.add_subplot(122)\n",
    "line_one, = plt.plot(val_loss, label='Validation')\n",
    "line_two, = plt.plot(train_loss, label = 'Training')\n",
    "plt.ylabel('Loss values')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.legend(handles=[line_one, line_two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracies \n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "fig = plt.figure()\n",
    "a=fig.add_subplot(121)\n",
    "line_one, = plt.plot(val_accuracy, label='Validation')\n",
    "line_two, = plt.plot(train_accuracy, label = 'Training')\n",
    "plt.ylabel('Accuracy values')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.legend(handles=[line_one, line_two])\n",
    "\n",
    "a=fig.add_subplot(122)\n",
    "line_one, = plt.plot(val_loss, label='Validation')\n",
    "line_two, = plt.plot(train_loss, label = 'Training')\n",
    "plt.ylabel('Loss values')\n",
    "plt.xlabel('No. of epochs')\n",
    "plt.legend(handles=[line_one, line_two])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at accuracy on test dataset by class label\n",
    "import itertools\n",
    "new_pred = list(itertools.chain.from_iterable(pred)) # Flatten list from the tensorflow\n",
    "new_pred2 = np.array(new_pred) # Convert list to array\n",
    "\n",
    "print(len(y_test), len(new_pred2))\n",
    "#print(y_test[:10], new_pred2[:10])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, new_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLot images corresponding to label class 27\n",
    "for i in np.where(y_train == 27):\n",
    "    res_27 = i[:3]\n",
    "\n",
    "    for i in range(3):\n",
    "        image = X_train[res_27[i]].squeeze()\n",
    "        plt.figure(figsize=(1,1))\n",
    "        plt.imshow(image)\n",
    "        print(y_train[res_27[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the images and resize to 32,32\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "size = 32,32\n",
    "paths = r'C:\\Users\\priya\\Documents\\carnd\\Term1\\CarND-Traffic-Sign-Classifier-P2\\test_images'\n",
    "new_path = os.path.join(paths,\"*.jpg\")\n",
    "for infile in glob.glob(new_path):\n",
    "    outfile = os.path.splitext(infile)[0] + \".small\"    \n",
    "    file, ext = os.path.splitext(infile)\n",
    "    im = Image.open(infile).convert('RGB')\n",
    "    out = im.resize((size))\n",
    "    out.save(outfile, \"JPEG\")\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image format\n",
    "im = Image.open(\"test_images/7.small\")\n",
    "print(im.format, im.size, im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert images to a dataset\n",
    "from scipy import ndimage\n",
    "new_path = os.path.join(paths,\"*.small\")\n",
    "image_size = 32\n",
    "pixel_depth = 255\n",
    "image_files = 8\n",
    "num_channels = 3\n",
    "dataset = np.ndarray(shape= (image_files, image_size, image_size, num_channels), dtype= np.float32)\n",
    "target = np.ndarray(shape= (image_files), dtype= np.int_)\n",
    "for filename in sorted(glob.glob(new_path)):                         \n",
    "  \n",
    "  try: \n",
    "      image_data = (ndimage.imread(filename, flatten = False).astype(float))/pixel_depth \n",
    "      if image_data.shape != (image_size, image_size, num_channels):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      imname = os.path.basename(filename)\n",
    "      name = int(imname.split(\".\")[0])\n",
    "      dataset[name, :, :, :] = image_data\n",
    "      target[name] = 0\n",
    "  except IOError as e:\n",
    "      print('Could not read:', filename, ':', e, '- it\\'s ok, skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Stats on the dataset\n",
    "print('Dataset shape:', dataset.shape)\n",
    "print('Target shape:', target.shape)\n",
    "print('Dataset Mean:', np.mean(dataset))\n",
    "print('Dataset Standard deviation:', np.std(dataset))\n",
    "print('Dataset Max:', np.amax(dataset))\n",
    "print('Dataset Min:', np.amin(dataset))\n",
    "print('Target shape:', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all 19 images\n",
    "for index in range(dataset.shape[0]):\n",
    "    image = dataset[index].squeeze()\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run model on new images and generate predictions. The predictions were compared with actual using signnames.csv\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy, pred, _ = evaluate(dataset, target)\n",
    "    \n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "\n",
    "i=0\n",
    "index_xtrain = []\n",
    "index_new = [1, 17, 5, 13, 18]\n",
    "\n",
    "for j in np.where(y_train == 13):\n",
    "    res_13 = j[:1]\n",
    "index_xtrain.append(res_13)\n",
    "\n",
    "for j in np.where(y_train == 1):\n",
    "    res_1 = j[:1]\n",
    "index_xtrain.append(res_1)\n",
    "\n",
    "for j in np.where(y_train == 28):\n",
    "    res_28 = j[:1]\n",
    "index_xtrain.append(res_28)\n",
    "\n",
    "for j in np.where(y_train == 34):\n",
    "    res_34 = j[:1]\n",
    "index_xtrain.append(res_34)\n",
    "\n",
    "for j in np.where(y_train == 14):\n",
    "    res_14 = j[:1]\n",
    "index_xtrain.append(res_14)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    fig = plt.figure()\n",
    "\n",
    "    a=fig.add_subplot(2,2,1)\n",
    "    image1 = X_train[index_xtrain[i]].squeeze()\n",
    "    plt.imshow(image1)\n",
    "    print(y_train[index_xtrain[i]])\n",
    "    a.set_title('Original X_train')\n",
    "\n",
    "    a=fig.add_subplot(2,2,2)\n",
    "    image1 = dataset[index_new[i]].squeeze()\n",
    "    plt.imshow(image1)\n",
    "    a.set_title('New Image')\n",
    "    \n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here. Look at predictions on the training set\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    accuracy, pred, _ = evaluate(X_train, y_train)\n",
    "\n",
    "import itertools\n",
    "new_pred = list(itertools.chain.from_iterable(pred)) # Flatten list from the tensorflow\n",
    "new_pred2 = np.array(new_pred) # Convert list to array\n",
    "\n",
    "print(len(y_train), len(new_pred2))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, new_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it maybe having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = random.randint(0, len(X_valid))\n",
    "#image_input = X_valid[n]\n",
    "\n",
    "image_input = dataset[5]\n",
    "# Plot what we are passing to the network\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image_input)\n",
    "print(image_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    image_input = image_input.reshape(1,32,32,3)\n",
    "    conv_layer_1_visual = sess.graph.get_tensor_by_name('conv1:0')\n",
    "    outputFeatureMap(image_input,conv_layer_1_visual)\n",
    "    \n",
    "    conv_layer_2_visual = sess.graph.get_tensor_by_name('conv2:0')\n",
    "    outputFeatureMap(image_input,conv_layer_2_visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = dataset[7]\n",
    "# Plot what we are passing to the network\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image_test)\n",
    "print(image_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    image_test = image_test.reshape(1,32,32,3)\n",
    "    conv_layer_1_visual = sess.graph.get_tensor_by_name('conv1:0')\n",
    "    outputFeatureMap(image_test,conv_layer_1_visual)\n",
    "    \n",
    "    conv_layer_2_visual = sess.graph.get_tensor_by_name('conv2:0')\n",
    "    outputFeatureMap(image_test,conv_layer_2_visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
